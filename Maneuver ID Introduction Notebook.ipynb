{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e86445f-dc75-4f91-9c99-0f0d44544356",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e569e-efae-4348-980e-0590923e4ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download the Repo\n",
    "### Requirements \n",
    " - [Jupyter](https://jupyter.org/install)\n",
    " \n",
    "### Installing & Running\n",
    "The following code will download this repo and open it in Jupyter so you can follow along and execute the code.\n",
    "```bash\n",
    "git clone https://github.com/bmswens/Maneuver-ID-Introduction-Notebook.git\n",
    "cd Maneuver-ID-Introduction-Notebook\n",
    "pip install notebook\n",
    "jupyter notebook 'Maneuver ID Introduction Notebook.ipynb'\n",
    "```\n",
    "\n",
    "## Website\n",
    "https://maneuver-id.mit.edu/\n",
    "## About\n",
    "The U.S. Air Force released a dataset from Pilot Training Next (PTN) through the AI Accelerator of Air Force pilots and trainees flying in virtual reality simulators. In an effort to enable AI coaching and automatic maneuver grading in pilot training, the Air Force seeks to automatically identify and label each maneuver flown in this dataset from a catalog of around 30 maneuvers. Your solution helps advance the state of the art in flying training!\n",
    "## The Challenge(s)\n",
    "\n",
    "1. Sorting \"useful\" vs \"non-useful\" data\n",
    "2. Separating \"useful\" data\n",
    "3. Identifying Maneuvers\n",
    "4. Grading Maneuvers\n",
    "\n",
    "## Scope\n",
    "This notebook aims to take you through seeing and understanding the data for the first time, all the way to creating a convolutional neural network aimed at answering challenge #1.\n",
    "\n",
    "## Maneuvers\n",
    "There are 18 maneuvers, but many have sub-classes, for a total of 29 maneuvers, listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a89be-7309-4761-ab99-0a43f336faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "maneuvers = [\n",
    "    'UndershootingTPStall', # undershooting traffic pattern stall\n",
    "    'AileronRoll',\n",
    "    '60SteepTurn', # turn performed at 60 deg bank\n",
    "    'BarrelRoll',\n",
    "    'SplitS',\n",
    "    'ILS', # Instrument landing system aproach\n",
    "    'StraightIn',\n",
    "    'OverheadPattern',\n",
    "    'ClosedPullup',\n",
    "    'ELP-PEL', # Emergency landing pattern, precautionary emergency landing\n",
    "    'Cuban8',\n",
    "    'UnusualAttitudeNoseHigh',\n",
    "    'Loop',\n",
    "    'NoseLowRecovery',\n",
    "    'VerticalSalpha',\n",
    "    'VerticalSbravo',\n",
    "    'UnusualAttitudeNoseLow',\n",
    "    'IntentionalSpin',\n",
    "    'SlowFlight',\n",
    "    'Immelman',\n",
    "    'Lazy8',\n",
    "    'NoseHighRecovery',\n",
    "    'PowerOnStallNoseLowTurning',\n",
    "    'ELP-FL', # Emergency landing pattern, forced landing\n",
    "    'LandingAttitudeTPStall', # landing traffic pattern stall\n",
    "    '45SteepTurn', # turn performed at 45 deg bank\n",
    "    'OvershootingTPStall', # overshooting traffic pattern stall\n",
    "    'Localizer',\n",
    "    'PowerOnStallNoseHighTurning'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfbb750-17b4-4fb6-8602-6dbe061a9c6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "More information on some of these maneuvers can be found here: http://maneuver-id.mit.edu/maneuvers-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66162801-bb11-44d5-8e61-048a285487ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e36a58-fa1d-44ae-a6bf-84483d4593dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Meta\n",
    "Data is stored in .tsv format with the following headers and data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b30d73-ffc2-4b33-9661-218d4ee0944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"\": int, # one up numbering system\n",
    "    \"time (sec)\": float,\n",
    "    \"xEast (m)\": float,\n",
    "    \"yNorth (m)\": float,\n",
    "    \"zUp (m)\": float,\n",
    "    \"vx (m/s)\": float,\n",
    "    \"xy (m/s)\": float,\n",
    "    \"vz (m/s)\": float,\n",
    "    \"head (deg)\": float,\n",
    "    \"pitch (deg)\": float,\n",
    "    \"roll (deg)\": float\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9071c-071b-4188-9973-3a095ac9a3a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading\n",
    "Python provides the built-in `csv` module that we can use to import .tsv files.\n",
    "\n",
    "---\n",
    "**Caveat**\n",
    "\n",
    "The files may sometimes contained malformed rows which don't cast to the data type they're supposed to. In this tutorial we will skip those rows with the assumption that the overall track will still provide an intelligible track.\n",
    "\n",
    "This behavior can be modified in the `clean_row` function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561f68c-eb85-4cb0-8ddf-1b925873ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def clean_row(row):\n",
    "    \"\"\"\n",
    "    This function is used to determine if a row should get added to the dataset.\n",
    "    If this function returns a \"truthy\" value, the clean function will append the returned value.\n",
    "    Else if it returns a \"falsey\" value, it will skip the row.\n",
    "    \n",
    "    Inputs:\n",
    "    row -- The input row as a dictionary\n",
    "    \n",
    "    Outputs:\n",
    "    output -- Either:\n",
    "        A. The cleaned version of the input row, as a dictionary\n",
    "        B. A \"falsey\" value\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    for header in row:\n",
    "        value = row[header]\n",
    "        try:\n",
    "            output[header] = float(value)\n",
    "        except:\n",
    "            return False\n",
    "    return output\n",
    "        \n",
    "\n",
    "def load(path):\n",
    "    \"\"\"\n",
    "    This function takes in a file path and returns the content as a list of dictionaries.\n",
    "    \n",
    "    Inputs:\n",
    "    path -- path to the .tsv file on the disk\n",
    "    \n",
    "    Outputs:\n",
    "    output -- list of dictionaries\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    with open(path) as incoming:\n",
    "        reader = csv.DictReader(incoming, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            cleaned_row = clean_row(row)\n",
    "            if cleaned_row:\n",
    "                output.append(cleaned_row)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ffbe3-3039-4a88-9e9c-f3cac5ff1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load('flights/example.tsv')\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93254428-f003-4a3e-9732-02ef7e1c5c44",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing\n",
    "\n",
    "Visualization is an important part of enabling the human portion of human-machine teaming. It allows us to quickly understand the data, and perhaps even verify that our models are on the right path.\n",
    "\n",
    "In this notebook, we'll use [Ploty](https://plotly.com/python/) for interactive visualizations, but [Matplotlib](https://matplotlib.org/) is another common library, especially in the scientific community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba2cbed-f67a-47bc-ab02-b3c44a029a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install chart_studio\n",
    "!{sys.executable} -m pip install kaleido\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "def visualize_3D(\n",
    "    data,\n",
    "    x_field=\"xEast (m)\",\n",
    "    y_field=\"yNorth (m)\",\n",
    "    z_field=\"zUp (m)\",\n",
    "    path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the data to an interactive 3D graph. Saves the graph to a file if path is provided.\n",
    "    \n",
    "    Inputs:\n",
    "    data -- List: A list of dictionaries containing the data to plot\n",
    "    x_field -- String: The name of the key for X data\n",
    "    y_field -- String: The name of the key for Y data\n",
    "    z_field -- String: The name of the key for Z data\n",
    "    path -- String: The path to save the file to on disk.\n",
    "    \n",
    "    Outputs:\n",
    "    None\n",
    "    \"\"\"\n",
    "    x = [row[x_field] for row in data]\n",
    "    y = [row[y_field] for row in data]\n",
    "    z = [row[z_field] for row in data]\n",
    "    plot = go.Scatter3d(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        z=z,\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        line=dict(\n",
    "            color='black',\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=plot)\n",
    "    fig.update_layout(\n",
    "        autosize=True,\n",
    "        scene=dict(\n",
    "            camera=dict(\n",
    "                up=dict(\n",
    "                    x=0,\n",
    "                    y=0,\n",
    "                    z=1\n",
    "                ),\n",
    "                eye=dict(\n",
    "                    x=0,\n",
    "                    y=1.0707,\n",
    "                    z=1,\n",
    "                )\n",
    "            ),\n",
    "            aspectratio = dict( x=1, y=1, z=0.7 ),\n",
    "            aspectmode = 'manual'\n",
    "        ),\n",
    "    )\n",
    "    if path:\n",
    "        if \".png\" in path:\n",
    "            fig.write_image(path)\n",
    "        else:\n",
    "            fig.write_html(path)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "def visualize_2D(data, y_field, x_field=None, path=None):\n",
    "    \"\"\"\n",
    "    Plots the data to an interactive 2d graph. Saves the graph to a file if path is provided.\n",
    "    \n",
    "    Inputs:\n",
    "    data -- List: A list of dictionaries containing the data to plot\n",
    "    x_field -- String: The name of the key for X data, defaults to index of Y field\n",
    "    y_field -- String: The name of the key for Y data\n",
    "    path -- String: The path to save the file to on disk.\n",
    "    \n",
    "    Outputs:\n",
    "    None\n",
    "    \"\"\"\n",
    "    y = [row[y_field] for row in data]\n",
    "    if x_field:\n",
    "        x = [row[x_field] for row in data]\n",
    "    else:\n",
    "        x = [index for index, _ in enumerate(y)]\n",
    "    plot = go.Scatter(\n",
    "        x=x, \n",
    "        y=y,\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        line=dict(\n",
    "            color='black',\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=plot)\n",
    "    fig.update_layout(\n",
    "        autosize=True,\n",
    "        scene=dict(\n",
    "            camera=dict(\n",
    "                up=dict(\n",
    "                    x=0,\n",
    "                    y=0,\n",
    "                    z=1\n",
    "                ),\n",
    "                eye=dict(\n",
    "                    x=0,\n",
    "                    y=1.0707,\n",
    "                    z=1,\n",
    "                )\n",
    "            ),\n",
    "            aspectratio = dict( x=1, y=1, z=0.7 ),\n",
    "            aspectmode = 'manual'\n",
    "        ),\n",
    "    )\n",
    "    if path:\n",
    "        if \".png\" in path:\n",
    "            fig.write_image(path)\n",
    "        else:\n",
    "            fig.write_html(path)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580afdfc-1552-461c-8865-8291bf2692a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_3D(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449cbcc-55d3-420e-af77-5594dc8fbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_2D(data, \"zUp (m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa2696-5cf5-4c16-8fe6-7ef2afdcdcc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Understanding The Data\n",
    "\n",
    "---\n",
    "\n",
    "**Caveat**\n",
    "\n",
    "The flight simulator that provided this data has some unique functions to it that are normally not possible in regular flight.\n",
    "* Pilots can teleport the plane from the runway into the air\n",
    "* Pilots can \"snap\" the plane to headings, pitches, and roles that would normally be too large of a change\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840d2d2-e157-4056-a0f3-06583ce81ceb",
   "metadata": {},
   "source": [
    "### Time\n",
    "Units: Seconds\n",
    "\n",
    "This column is the number of seconds since the flight began, often in intervals of roughly 0.1 seconds.\n",
    "### xEast, yNorth, zUp\n",
    "Units: Meters\n",
    "\n",
    "These columns plot where the plane is at a given point in time and can be thought of similiar to lattiude, longitude, and altitude.\n",
    "### vx, vy, vz\n",
    "Units: Meters per second\n",
    "\n",
    "Stands for: Velocity in the given axis.\n",
    "\n",
    "These columns denote the current speed of the aircraft in a given axis.\n",
    "### Head\n",
    "Units: Degrees\n",
    "\n",
    "This will help indicate the direction that the aircraft is flying in. Combined with a non-zero velocity, this field can be used to calculate where the next data point would be (xEast and yNorth).\n",
    "### Pitch\n",
    "Units: Degrees\n",
    "\n",
    "This will help indicate if an aircraft is ascending or descending. Combined with a non-zero veloicty, can be used to calcluate the zUp of the next data point.\n",
    "### Roll\n",
    "Units: Degrees\n",
    "\n",
    "Indicates the orientation of the aircraft. 0 is what we would generally relate with \"right side up\" and 180 would be \"upside down.\"\n",
    "\n",
    "---\n",
    "\n",
    "The following image can be used to help understand head (heading), pitch, and roll.\n",
    "\n",
    "---\n",
    "\n",
    "![pitch-heading-roll.png](https://www.researchgate.net/profile/Tsouknidas-Nikolaos-2/publication/220720660/figure/fig7/AS:668413135429636@1536373518155/Examples-of-Heading-Pitch-and-Roll-on-an-aircraft.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ac544-4cd9-47a3-859c-40e0e6c38ecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing / Data Wrangling\n",
    "Preprocessing your data can sometimes be just as important as the actual model architecture itself.\n",
    "\n",
    "Below are some examples of preprocessing that could be done to the data. Not all will necessarily provide an impact, and some may even have negative results. These are just to provide examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c814f6b-abb8-4c1b-8a1e-6354642b0b3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove Runway Data\n",
    "In this process we aim to (naively) remove datapoints that occur on or near the runway.\n",
    "\n",
    "Reasoning: A pilot is hopefully not performing maneuvers near the ground or runway, as that would be dangerous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2758a8-46d3-43fb-9eac-d04ccdd5a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_runway_data(data, minimum=100):\n",
    "    output = []\n",
    "    for row in data:\n",
    "        if row[\"zUp (m)\"] >= minimum:\n",
    "            output.append(row)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3763587-303d-4a12-bf68-5de4c8773aa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate Airspeed\n",
    "In this process, we're going to remove the independent `vx (m/s)`, `vy (m/s)`, and `vz (m/s)` fields, and add them into a single field, then remove the three fields used to calculate it.\n",
    "\n",
    "Reason: The written parameters of what define a good maneuver vs a bad maneuver take airspeed into account in order to avoid stalls and going above operation limitations of the aircraft. Airspeed = Ground Speed - Wind Speed. Our three velocities are in relation to the ground so in order to calculate the airspeed of the aircraft we have to assume that there is zero wind for the entirety of the flight. With zero wind, we now have Airspeed = Ground Speed. Treating the three velocities as components of a vector we can calculate the magnitude of the vector to give us airspeed with a helper method. Since our velocities units are given to us in m/s we need to convert it to knots with a helper method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbb550c-51a2-4c55-a622-f33b14b37a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ms_to_knot(x):\n",
    "    # m/s * 60s/min * 60min/hr * nm/1852m\n",
    "    return x * ((60 ** 2) / 1852)\n",
    "\n",
    "def calc_3d_vector_magnitude(x, y, z):\n",
    "    # For help with understanding magnitude of a vector please visit link.\n",
    "    # https://www.cuemath.com/magnitude-of-a-vector-formula/\n",
    "    return ((x ** 2) + (y ** 2) + (z ** 2)) ** 0.5\n",
    "\n",
    "def calculate_airspeed(data):\n",
    "    output = []\n",
    "    for row in data:\n",
    "        vx = row[\"vx (m/s)\"]\n",
    "        vy = row[\"vy (m/s)\"]\n",
    "        vz = row[\"vz (m/s)\"]\n",
    "        magnitude = calc_3d_vector_magnitude(vx, vy, vz)\n",
    "        row.pop(\"vx (m/s)\", None)\n",
    "        row.pop(\"vy (m/s)\", None)\n",
    "        row.pop(\"vz (m/s)\", None)\n",
    "        row[\"airspeed (knot)\"] = convert_ms_to_knot(magnitude)\n",
    "        output.append(row)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220355c7-61f8-4728-9806-438bfc7b87e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Making A Model\n",
    "Now we'll write a convolutional neural network (CNN) based on graphs of the `xEast` and `yNorth` fields (it will visualize as though we were looking at the flight path from a top-down perspective) to see if it can classify the flights in accordance with the labled data.\n",
    "\n",
    "---\n",
    "\n",
    "**Caveat**\n",
    "\n",
    "In order to accomplish this part of the notebook, you will have have to have access to the dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf1549-7202-4d85-9a7a-c9d1045301d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these based on your file paths\n",
    "train_path = \"flights/labeled/train\"\n",
    "test_path = \"flights/labeled/test\"\n",
    "\n",
    "# precentage of training data to use as training vs validation\n",
    "train_percentage = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74fe47-b889-4a92-a2a5-041c6a694b34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Making a Dataset\n",
    "Our dataset is going to be based off of the PNG representation of the flight, from a top down perspective.\n",
    "\n",
    "Images will be saved to `{path}_img` folder.\n",
    "\n",
    "You can modify this `Dataset` class to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666f620-22f3-4c8a-9656-e82c6e17cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1b54e-505c-4d33-b0e9-2392f3a544ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in\n",
    "import os\n",
    "import csv\n",
    "# 3rd party\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class FlightsAsImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This class will load and convert all flights to graphs as a .png\n",
    "    The graphs are based on 'xEast' and 'yNorth' and represent a top-down view of the flight.\n",
    "    \n",
    "    Params:\n",
    "    size - the height and width of the output .png\n",
    "    make - whether or not to generate the image (false allows you to skip making the image if it already exists)\n",
    "    \"\"\"\n",
    "    def __init__(self, path, size=128, make=True):\n",
    "        self.all_labels = [folder for folder in os.listdir(path) if 'img' not in folder]\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.size = size\n",
    "        for label in self.all_labels:\n",
    "            for f in os.listdir(os.path.join(path, label)):\n",
    "                if f.startswith('.') or '.tsv' not in f:\n",
    "                    continue\n",
    "                new_path = self.convert_to_png(os.path.join(path, label, f), make)\n",
    "                self.images.append(new_path)\n",
    "                self.labels.append(label)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.images[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        array = np.array(img)\n",
    "        label = self.labels[idx]\n",
    "        if label == \"good\":\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        tensor = torchvision.transforms.ToTensor()(img)\n",
    "        # tensor = tensor.unsqueeze(0)\n",
    "        return tensor, label\n",
    "    \n",
    "    def convert_to_png(self, full_path, make):\n",
    "        \n",
    "        # flights/good_train/01.tsv -> flights/good_train_img/01.png\n",
    "        file_name = os.path.basename(full_path)\n",
    "        file_name = file_name.replace('.tsv', '.png')\n",
    "        \n",
    "        folder = os.path.dirname(full_path)\n",
    "        folder += '_img'\n",
    "        \n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        \n",
    "        new_path = os.path.join(folder, file_name)\n",
    "        \n",
    "        if make:\n",
    "            data = self.load(full_path)\n",
    "\n",
    "            y = [row[\"yNorth (m)\"] for row in data]\n",
    "            x = [row[\"xEast (m)\"] for row in data]\n",
    "            plot = go.Scatter(\n",
    "                x=x, \n",
    "                y=y,\n",
    "                marker=dict(\n",
    "                    size=2,\n",
    "                    color=\"black\"\n",
    "                ),\n",
    "                line=dict(\n",
    "                    color='black',\n",
    "                    width=2\n",
    "                )\n",
    "            )\n",
    "            fig = go.Figure(data=plot)\n",
    "            fig.update_layout(\n",
    "                margin=go.layout.Margin(\n",
    "                    l=0, #left margin\n",
    "                    r=0, #right margin\n",
    "                    b=0, #bottom margin\n",
    "                    t=0, #top margin\n",
    "                ),\n",
    "                height=self.size,\n",
    "                width=self.size,\n",
    "                scene=dict(\n",
    "                    camera=dict(\n",
    "                        up=dict(\n",
    "                            x=0,\n",
    "                            y=0,\n",
    "                            z=1\n",
    "                        ),\n",
    "                        eye=dict(\n",
    "                            x=0,\n",
    "                            y=1.0707,\n",
    "                            z=1,\n",
    "                        )\n",
    "                    ),\n",
    "                    aspectratio = dict( x=1, y=1, z=0.7 ),\n",
    "                    aspectmode = 'manual'\n",
    "                ),\n",
    "            )\n",
    "            fig.update_xaxes(showticklabels=False, showgrid=False)\n",
    "            fig.update_yaxes(showticklabels=False, showgrid=False)\n",
    "            fig.write_image(new_path)\n",
    "        return new_path\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_row(row):\n",
    "        output = {}\n",
    "        for header in row:\n",
    "            value = row[header]\n",
    "            try:\n",
    "                output[header.strip()] = float(value)\n",
    "            except:\n",
    "                return False\n",
    "        return output\n",
    "        \n",
    "    def load(self, full_path):\n",
    "        output = []\n",
    "        with open(full_path) as incoming:\n",
    "            reader = csv.DictReader(incoming, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                cleaned_row = self.clean_row(row)\n",
    "                if cleaned_row:\n",
    "                    output.append(cleaned_row)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb10cc-c043-4456-87eb-f51b3d4a2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our datasets\n",
    "train_data = FlightsAsImageDataset(train_path)\n",
    "test_data = FlightsAsImageDataset(test_path)\n",
    "\n",
    "# split training data into training and validation\n",
    "train_size = int(len(train_data) * train_percentage)\n",
    "val_size = len(train_data) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ad8b6-4d09-4f7e-b72b-be08fcbc2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the datasets into data loaders\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=1,\n",
    "    num_workers=4\n",
    ")\n",
    "val_data_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=1,\n",
    "    num_workers=4\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547e39b-c2f3-4b59-8c3e-d2b94bbed600",
   "metadata": {},
   "source": [
    "## Building The Model\n",
    "Here we'll build a CNN to train on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d948b1-3fcf-40fb-a637-abfbbfe3f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party\n",
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic convolutional neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # reused\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = torch.flatten\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # layer one\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        \n",
    "        # layer two\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
    "        \n",
    "        # connected layers\n",
    "        self.linear1 = nn.Linear(10092, 512)\n",
    "        self.linear2 = nn.Linear(512, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # first set of layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # second set of layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # connected\n",
    "        x = torch.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b28b73-4949-4ffa-86f8-91360dc09e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42aad9f-80e3-4f0b-b572-eb5f4046448c",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Here we'll do 5 passes at training the model, saving the best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6865cc-9ef5-4d5f-ba31-b8281b9c7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e89634-458f-4cf3-84ab-c12c05d4ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "def train_one_epoch(model, data, loss, optimizer):\n",
    "    total_loss = 0.\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for img, label in data:\n",
    "        pred_label = model(img)\n",
    "        l = loss(pred_label, label)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += l.item()\n",
    "        i += 1\n",
    "        if i % 500 == 0:\n",
    "            print(f'train: img {i} avg loss - {total_loss / i}')\n",
    "    return total_loss / len(data)\n",
    "\n",
    "\n",
    "def test_one_epoch(model, data, loss):\n",
    "    total_loss = 0.\n",
    "    model.eval()\n",
    "    i = 0\n",
    "    for img, label in data:\n",
    "        pred_label = model(img)\n",
    "        l = loss(pred_label, label)\n",
    "        total_loss += l.item()\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print(f'validate: img {i} avg loss - {total_loss / i}')\n",
    "    return total_loss / len(data)\n",
    "    \n",
    "best_loss = None\n",
    "print(f'training size - {len(train_data_loader)} validate size - {len(val_data_loader)}')\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_one_epoch(model, train_data_loader, loss, optimizer)\n",
    "    val_loss = test_one_epoch(model, val_data_loader, loss)\n",
    "    print(f'{epoch + 1}: train - {train_loss:.7f} test - {val_loss:.7f}')\n",
    "    if best_loss is None or val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        model_path = f'model_{epoch}'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d68ae-3aad-433d-8634-6302daa6aaf0",
   "metadata": {},
   "source": [
    "## Checking the Model\n",
    "Next we'll check the overall accuracy of the model on our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01add37-7c41-4b12-b8fb-e4a67adfbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for img, label in test_data_loader:\n",
    "    model.eval()\n",
    "    pred = model(img)\n",
    "    rounded_pred = round(pred.item())\n",
    "    if rounded_pred == label:\n",
    "        correct += 1\n",
    "print(f'{(correct / len(test_data_loader)) * 100:.4f}% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbfc760-5303-4007-a5ba-6cd7db04e3c1",
   "metadata": {},
   "source": [
    "Now we'll load up 5 random flights and see how our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a905359-7ac0-4b95-b9e3-47a23aada1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as PyImage\n",
    "import random\n",
    "\n",
    "for _ in range(5):\n",
    "    index = random.randint(0, len(test_data) - 1)\n",
    "    path = test_data.images[index]\n",
    "    img, label = test_data[index]\n",
    "    predicted = model(img.unsqueeze(0))\n",
    "    display(PyImage(filename=path))\n",
    "    print(f'Predicted: {round(predicted.item())}; Actual: {label}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c2c45c-bf59-4fbc-87d5-a2c442d89100",
   "metadata": {},
   "source": [
    "# The End\n",
    "After this, you should now have all the resources necessary to start tweaking the model, or dataset, or both to produce a higher degree of accuracy.\n",
    "\n",
    "Listed below are a few ideas to get your started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb385d9-5055-4195-be46-f9a2016a916d",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "- Change the size of the images (512x512 is slower but increases to ~96% accuracy)\n",
    "- Create a deeper CNN\n",
    "- Add the altitude over time as another layer to the CNN\n",
    "- Modify the dataset to instead analyze the underlying data\n",
    "- Apply transformations (such as rotation or cropping) to the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089d241-5126-4a37-82b7-7d46695acc95",
   "metadata": {},
   "source": [
    "## Contributors\n",
    " - [Brandon Swenson](https://github.com/bmswens) - Author\n",
    " - Jonathan Hurrell - Feedback\n",
    " - Kyle McAplin - Feedback\n",
    " - Armando Cabrera - Feedback\n",
    " - [Chantz Yazzie](https://github.com/chantzyaz) - Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a370a-a52c-4ef9-8629-3e0e3cd70b35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Acknowledgment\n",
    "If you would like to acknowledge this notebook in your paper or report, we recommend the following:\n",
    "\n",
    "> The authors acknowledge the Maneuver ID Introduction Notebook for providing learning resources that have contributed to the research results reported within this paper/report.\n",
    "\n",
    "Thank you for acknowledging us – we appreciate it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
